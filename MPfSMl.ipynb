{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "Modelo = \"medium\" # @param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6Frc5sa7N-IN"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√≥digo\n",
        "N√£o precisa mexer, aqui tem os prompts, caso queira alterar."
      ],
      "metadata": {
        "id": "CUr5XDKOSCAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instala√ß√£o das Biliotecas"
      ],
      "metadata": {
        "id": "gpAcb1VmMT_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install whisper weasyprint"
      ],
      "metadata": {
        "id": "eDgZx_fOMMta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ed8d98-73a0-4ff4-e70a-14a37b5b7097"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: whisper in /usr/local/lib/python3.11/dist-packages (1.1.10)\n",
            "Requirement already satisfied: weasyprint in /usr/local/lib/python3.11/dist-packages (65.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from whisper) (1.17.0)\n",
            "Requirement already satisfied: pydyf>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (0.11.0)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (1.17.1)\n",
            "Requirement already satisfied: tinyhtml5>=2.0.0b1 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (2.0.0)\n",
            "Requirement already satisfied: tinycss2>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (1.4.0)\n",
            "Requirement already satisfied: cssselect2>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (0.8.0)\n",
            "Requirement already satisfied: Pyphen>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (0.17.2)\n",
            "Requirement already satisfied: Pillow>=9.1.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (11.1.0)\n",
            "Requirement already satisfied: fonttools>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (4.57.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=0.6->weasyprint) (2.22)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from cssselect2>=0.8.0->weasyprint) (0.5.1)\n",
            "Requirement already satisfied: brotli>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (1.1.0)\n",
            "Requirement already satisfied: zopfli>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (0.2.3.post1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper"
      ],
      "metadata": {
        "id": "ChKyonQ3G5yo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "febc40c0-a07d-48de-e5bf-76c6be2871d0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "VCkLMWPYLo3E"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import argparse\n",
        "import os\n",
        "from datetime import datetime\n",
        "import torch\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import requests\n",
        "import markdown\n",
        "from weasyprint import HTML\n",
        "import shutil\n",
        "from google.colab import userdata\n",
        "from google.colab import files\n",
        "\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={API_KEY}\""
      ],
      "metadata": {
        "id": "KJNrXlH-MHBl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notion_style = \"\"\"\n",
        "<style>\n",
        "  body {\n",
        "      font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial, sans-serif, \"Segoe UI Emoji\", \"Apple Color Emoji\";\n",
        "      max-width: 800px;\n",
        "      margin: 10px auto;\n",
        "      padding: 10px;\n",
        "      line-height: 1.6;\n",
        "      font-size: 16px;\n",
        "      color: #2e2e2e;\n",
        "      background: #ffffff;\n",
        "  }\n",
        "    h1, h2, h3 {\n",
        "        border-bottom: 1px solid #eaeaea;\n",
        "        padding-bottom: 0.3em;\n",
        "        margin-top: 1.4em;\n",
        "    }\n",
        "    code {\n",
        "        background-color: #f6f8fa;\n",
        "        padding: 2px 4px;\n",
        "        border-radius: 3px;\n",
        "        font-size: 90%;\n",
        "        font-family: SFMono-Regular, Consolas, Liberation Mono, Menlo, monospace;\n",
        "    }\n",
        "    pre code {\n",
        "        background-color: #f6f8fa;\n",
        "        display: block;\n",
        "        padding: 1em;\n",
        "        overflow-x: auto;\n",
        "    }\n",
        "    blockquote {\n",
        "        border-left: 4px solid #dfe2e5;\n",
        "        padding: 0 1em;\n",
        "        color: #6a737d;\n",
        "    }\n",
        "    table {\n",
        "        border-collapse: collapse;\n",
        "        width: 100%;\n",
        "    }\n",
        "    th, td {\n",
        "        border: 1px solid #dfe2e5;\n",
        "        padding: 6px 13px;\n",
        "    }\n",
        "    th {\n",
        "        background-color: #f6f8fa;\n",
        "    }\n",
        "    @page {\n",
        "        margin: 10mm;\n",
        "    }\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "63CBt_yQMpN5"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def argumentos_cli():\n",
        "    parser = argparse.ArgumentParser(description=\"Transcri√ß√£o e resumo de aulas com Whisper + Gemini\")\n",
        "\n",
        "    parser.add_argument('--audio', type=str, help='Caminho para o arquivo de √°udio a ser processado')\n",
        "    parser.add_argument('--modelo', type=str, default='base', help='Modelo do Whisper a ser usado (base, small, medium, large, etc.)')\n",
        "\n",
        "    return parser.parse_args()\n"
      ],
      "metadata": {
        "id": "u60zOcwAMsn6"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_pdf_markdown(markdown_text, pasta_destino, nome_pdf):\n",
        "    html_content = markdown.markdown(markdown_text, extensions=[\"extra\", \"tables\", \"fenced_code\"])\n",
        "    full_html = f\"<!DOCTYPE html><html><head><meta charset='utf-8'>{notion_style}</head><body>{html_content}</body></html>\"\n",
        "    caminho_pdf = os.path.join(pasta_destino, nome_pdf)\n",
        "    HTML(string=full_html).write_pdf(caminho_pdf)\n",
        "    print(f\"‚úÖ PDF gerado com sucesso: {caminho_pdf}\")"
      ],
      "metadata": {
        "id": "ZkIV-LEhM0jO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts enviados ao gemini"
      ],
      "metadata": {
        "id": "KzYluOjJMl4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_guia_estudos_markdown(transcricao: str) -> tuple[str, str]:\n",
        "    prompt_estudo = f\"\"\"\n",
        "A partir do conte√∫do abaixo (resumo), crie uma guia de estudos personalizada em formato Markdown, com foco em aprendizado acad√™mico e m√©dico.\n",
        "\n",
        "A resposta ser√° convertida em PDF, ent√£o:\n",
        "\n",
        "- Use formata√ß√£o Markdown limpa\n",
        "- Use t√≠tulos, listas e divis√µes visuais claras\n",
        "- N√£o inclua elementos interativos ou links clic√°veis\n",
        "\n",
        "Contexto essencial:\n",
        "\n",
        "Este resumo foi gerado a partir de um sistema automatizado que converte √°udios de estudo em texto. A partir dele, ser√£o produzidos:\n",
        "\n",
        "- Quest√µes objetivas e cl√≠nicas, classificadas por dificuldade\n",
        "- Flashcards com os principais pontos e termos\n",
        "\n",
        "Por isso, a guia de estudos deve:\n",
        "\n",
        "- Indicar os conhecimentos pr√©vios essenciais para compreender o tema\n",
        "- Apresentar um checklist organizado com o que estudar primeiro\n",
        "- Explicar como e quando utilizar as quest√µes e flashcards gerados\n",
        "- Evitar sugest√µes gen√©ricas como \"ensinar a algu√©m\" ou \"fazer resumos pr√≥prios\"\n",
        "\n",
        "A estrutura da resposta deve ser:\n",
        "\n",
        "# Guia de Estudos: [Tema do Resumo]\n",
        "\n",
        "## Vis√£o Geral\n",
        "Descreva em poucas linhas o tema central e sua relev√¢ncia m√©dica.\n",
        "\n",
        "## Pr√©-requisitos\n",
        "Liste t√≥picos que o estudante deve dominar antes de aprofundar o conte√∫do. Ex: anatomia relacionada, princ√≠pios b√°sicos, etc.\n",
        "\n",
        "## Checklist de Estudo\n",
        "Organize os principais pontos do conte√∫do em forma de lista ordenada. Cada item deve representar uma etapa de estudo.\n",
        "\n",
        "## Aplica√ß√£o Direta\n",
        "Oriente o estudante a:\n",
        "\n",
        "- Usar as quest√µes geradas para treinar sua compreens√£o e identificar lacunas\n",
        "- Utilizar os flashcards para revis√£o cont√≠nua e memoriza√ß√£o\n",
        "- Revisar frequentemente os erros nas quest√µes para refor√ßar √°reas fr√°geis\n",
        "\n",
        "N√£o inclua sugest√µes gen√©ricas como ensinar o conte√∫do para outra pessoa.\n",
        "\n",
        "## Plano de Estudo Sugerido\n",
        "Organize um cronograma de revis√£o dividido por dias (ex: 3, 7 ou 14 dias), integrando o uso das quest√µes e dos flashcards gerados com o resumo.\n",
        "\n",
        "Resumo para base do estudo:\n",
        "{transcricao}\n",
        "\"\"\"\n",
        "\n",
        "    data = {\"contents\": [{\"parts\": [{\"text\": prompt_estudo}]}]}\n",
        "\n",
        "    response = requests.post(URL, headers=headers, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        markdown_raw = result['candidates'][0]['content']['parts'][0]['text']\n",
        "\n",
        "        markdown_clean = markdown_raw.strip().split(\"\\n\", 1)[-1].strip()  # Clean and trim the result\n",
        "\n",
        "        titulo = next((line.strip(\"# \").strip() for line in markdown_clean.split(\"\\n\") if line.startswith(\"# \")), \"Guia\")\n",
        "        return f\"{titulo}.pdf\", markdown_clean\n",
        "    else:\n",
        "        raise Exception(f\"Erro na requisi√ß√£o: {response.status_code}\\n{response.text}\")\n"
      ],
      "metadata": {
        "id": "o1YK3vkeM4_o"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_resumo_markdown(transcricao: str) -> tuple[str, str]:\n",
        "    prompt = f\"\"\"\n",
        "Sem fornecer nenhum tipo de feedback, coment√°rio ou explica√ß√£o adicional, gere um resumo completo e did√°tico da transcri√ß√£o da aula que vou enviar a seguir. O objetivo √© facilitar a compreens√£o de um aluno de medicina, ent√£o complemente com informa√ß√µes relevantes sempre que considerar √∫til para a assimila√ß√£o do conte√∫do.\n",
        "\n",
        "O resumo deve ser entregue em Markdown puro, como se fosse um c√≥digo-fonte, com t√≠tulos estilizados com emojis, no estilo visual do Notion.\n",
        "\n",
        "Apenas retorne o conte√∫do em Markdown, sem nenhuma outra resposta textual.\n",
        "\n",
        "Transcri√ß√£o da aula:\n",
        "{transcricao}\n",
        "\"\"\"\n",
        "\n",
        "    data = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"parts\": [\n",
        "                    {\"text\": prompt}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(URL, headers=headers, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        markdown_raw = result['candidates'][0]['content']['parts'][0]['text']\n",
        "\n",
        "        if markdown_raw.startswith(\"```markdown\") and markdown_raw.endswith(\"```\"):\n",
        "            markdown_clean = \"\\n\".join(markdown_raw.strip().split(\"\\n\")[1:-1])\n",
        "        else:\n",
        "            markdown_clean = markdown_raw\n",
        "\n",
        "        titulo = \"\"\n",
        "        for line in markdown_clean.split(\"\\n\"):\n",
        "            if line.strip().startswith(\"# \"):\n",
        "                titulo = line.strip(\"# \").strip()\n",
        "                break\n",
        "\n",
        "        titulo = titulo + '.pdf'\n",
        "        return titulo, markdown_clean\n",
        "    else:\n",
        "        raise Exception(f\"Erro na requisi√ß√£o: {response.status_code}\\n{response.text}\")\n"
      ],
      "metadata": {
        "id": "LaweMHgvJ1cx"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_resumo_markdown(transcricao: str) -> tuple[str, str]:\n",
        "    prompt = f\"\"\"\n",
        "Sem fornecer nenhum tipo de feedback, coment√°rio ou explica√ß√£o adicional, gere um resumo completo e did√°tico da transcri√ß√£o da aula que vou enviar a seguir. O objetivo √© facilitar a compreens√£o de um aluno de medicina, ent√£o complemente com informa√ß√µes relevantes sempre que considerar √∫til para a assimila√ß√£o do conte√∫do.\n",
        "\n",
        "O resumo deve ser entregue em Markdown puro, como se fosse um c√≥digo-fonte, com t√≠tulos estilizados com emojis, no estilo visual do Notion.\n",
        "\n",
        "Apenas retorne o conte√∫do em Markdown, sem nenhuma outra resposta textual.\n",
        "\n",
        "Transcri√ß√£o da aula:\n",
        "{transcricao}\n",
        "\"\"\"\n",
        "\n",
        "    data = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"parts\": [\n",
        "                    {\"text\": prompt}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(URL, headers=headers, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        markdown_raw = result['candidates'][0]['content']['parts'][0]['text']\n",
        "\n",
        "        if markdown_raw.startswith(\"```markdown\") and markdown_raw.endswith(\"```\"):\n",
        "            markdown_clean = \"\\n\".join(markdown_raw.strip().split(\"\\n\")[1:-1])\n",
        "        else:\n",
        "            markdown_clean = markdown_raw\n",
        "\n",
        "        titulo = \"\"\n",
        "        for line in markdown_clean.split(\"\\n\"):\n",
        "            if line.strip().startswith(\"# \"):\n",
        "                titulo = line.strip(\"# \").strip()\n",
        "                break\n",
        "\n",
        "        titulo = titulo + '.pdf'\n",
        "        return titulo, markdown_clean\n",
        "    else:\n",
        "        raise Exception(f\"Erro na requisi√ß√£o: {response.status_code}\\n{response.text}\")\n"
      ],
      "metadata": {
        "id": "ZULuRHcmJy5E"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_resumo_markdown(transcricao: str) -> tuple[str, str]:\n",
        "    prompt = f\"\"\"\n",
        "Sem fornecer nenhum tipo de feedback, coment√°rio ou explica√ß√£o adicional, gere um resumo completo e did√°tico da transcri√ß√£o da aula que vou enviar a seguir. O objetivo √© facilitar a compreens√£o de um aluno de medicina, ent√£o complemente com informa√ß√µes relevantes sempre que considerar √∫til para a assimila√ß√£o do conte√∫do.\n",
        "\n",
        "O resumo deve ser entregue em Markdown puro, como se fosse um c√≥digo-fonte, com t√≠tulos estilizados com emojis, no estilo visual do Notion.\n",
        "\n",
        "Apenas retorne o conte√∫do em Markdown, sem nenhuma outra resposta textual.\n",
        "\n",
        "Transcri√ß√£o da aula:\n",
        "{transcricao}\n",
        "\"\"\"\n",
        "\n",
        "    data = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"parts\": [\n",
        "                    {\"text\": prompt}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(URL, headers=headers, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        markdown_raw = result['candidates'][0]['content']['parts'][0]['text']\n",
        "\n",
        "        if markdown_raw.startswith(\"```markdown\") and markdown_raw.endswith(\"```\"):\n",
        "            markdown_clean = \"\\n\".join(markdown_raw.strip().split(\"\\n\")[1:-1])\n",
        "        else:\n",
        "            markdown_clean = markdown_raw\n",
        "\n",
        "        titulo = \"\"\n",
        "        for line in markdown_clean.split(\"\\n\"):\n",
        "            if line.strip().startswith(\"# \"):\n",
        "                titulo = line.strip(\"# \").strip()\n",
        "                break\n",
        "\n",
        "        titulo = titulo + '.pdf'\n",
        "        return titulo, markdown_clean\n",
        "    else:\n",
        "        raise Exception(f\"Erro na requisi√ß√£o: {response.status_code}\\n{response.text}\")\n"
      ],
      "metadata": {
        "id": "riDGipHGM9X2"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_questoes_markdown(texto_base):\n",
        "    prompt = f\"\"\"\n",
        "    A partir do conte√∫do abaixo, crie 10 quest√µes de cada n√≠vel de dificuldade (f√°cil, m√©dio, dif√≠cil), com foco em refor√ßo de compreens√£o m√©dica e acad√™mica. Siga as regras:\n",
        "\n",
        "    - Crie 10 quest√µes f√°ceis, 10 m√©dias e 10 dif√≠ceis.\n",
        "    - N√£o agrupe as quest√µes em f√°ceis, m√©dias ou dificeis, o aluno s√≥ deve saber ao ver o gabarito.\n",
        "    - Fa√ßa da quest√£o 01 at√© a 30, sem agrupar por dificuldade.\n",
        "    - As respostas das quest√µes devem estar APENAS excluivamente na √°rea de gabaritos.\n",
        "    - As quest√µes devem ser formuladas em formatos variados:\n",
        "      - Quest√µes objetivas (com alternativas)\n",
        "      - Quest√µes de resposta curta\n",
        "      - Quest√µes de verdadeiro ou falso\n",
        "      - Casos cl√≠nicos\n",
        "\n",
        "    - As alternativas, ou as respostas curtas, devem ser realistas e educativas, com a resposta correta claramente identificada.\n",
        "    - As alternativas devem ser equilibradas em dificuldade, sem nenhuma √≥bvia ou excessivamente f√°cil.\n",
        "    - Cada quest√£o deve ser seguida de justificativa detalhada explicando o racioc√≠nio por tr√°s da resposta correta.\n",
        "    - N√£o forne√ßa explica√ß√µes adicionais al√©m das instru√ß√µes acima.\n",
        "\n",
        "    A sa√≠da deve estar no formato Markdown, com as quest√µes bem organizadas e agrad√°veis para visualiza√ß√£o e impress√£o. Evite usar links e mantenha a formata√ß√£o simples, para que as quest√µes sejam facilmente leg√≠veis e prontas para serem impressas. As alternativas devem ser listadas de forma clara, e cada justificativa deve vir logo ap√≥s a quest√£o correspondente.\n",
        "\n",
        "    Para as quest√µes de resposta curta, inclua um espa√ßo de linhas (sublinhado) do tamanho necess√°rio para a resposta, usando a seguinte formata√ß√£o:\n",
        "    ________________________\n",
        "\n",
        "    Sa√≠da: Responda no formato Markdown com as seguintes informa√ß√µes:\n",
        "\n",
        "    ### Quest√µes:\n",
        "\n",
        "    1.  **Pergunta:** (enunciado da quest√£o)\n",
        "       - Alternativas:\n",
        "         - A) Alternativa 1\n",
        "         - B) Alternativa 2\n",
        "         - C) Alternativa 3\n",
        "         - D) Alternativa 4\n",
        "         - E) Alternativa 5\n",
        "\n",
        "    2.  **Pergunta:** (enunciado da quest√£o)\n",
        "       - Alternativas:\n",
        "         - A) Verdadeiro\n",
        "         - B) Falso (justificar aqui:______________________________)\n",
        "\n",
        "    3. **Pergunta:** (enunciado da quest√£o)\n",
        "       **Resposta:**\n",
        "       _____________________________________________________________\n",
        "\n",
        "    Repita as 30 quest√µes, seguindo o mesmo formato\n",
        "\n",
        "    ### Gabarito:\n",
        "    1. **Resposta:** A\n",
        "       **Justificativa:** Explica√ß√£o detalhada do porqu√™ a alternativa A √© a correta.\n",
        "       **N√≠vel: f√°cil/m√©dio/dif√≠cil**\n",
        "\n",
        "    2. **Resposta:** B\n",
        "       **Justificativa:** Explica√ß√£o detalhada do porqu√™ a alternativa B √© a correta.\n",
        "       **N√≠vel: f√°cil/m√©dio/dif√≠cil**\n",
        "\n",
        "    3. **Resposta:** Falso\n",
        "       **Justificativa:** Explica√ß√£o detalhada do que tornou a quest√£o falsa ou verdadeira.\n",
        "       **N√≠vel: f√°cil/m√©dio/dif√≠cil**\n",
        "\n",
        "    (Repita para todas as quest√µes)\n",
        "\n",
        "    ### Texto base:\n",
        "    {texto_base}\n",
        "    \"\"\"\n",
        "    data = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n",
        "\n",
        "    response = requests.post(URL, headers=headers, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        markdown_raw = result['candidates'][0]['content']['parts'][0]['text']\n",
        "\n",
        "        markdown_clean = markdown_raw.strip().split(\"\\n\", 1)[-1].strip()  # Clean and trim the result\n",
        "\n",
        "        titulo = 'questoes'\n",
        "        return f\"{titulo}.pdf\", markdown_clean\n",
        "    else:\n",
        "        raise Exception(f\"Erro na requisi√ß√£o: {response.status_code}\\n{response.text}\")"
      ],
      "metadata": {
        "id": "5yuQ3rtdM2YZ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execu√ß√£o da Transcri√ß√£o e Passagem ao PDF."
      ],
      "metadata": {
        "id": "5CQDMTsaM8K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def escolher_dispositivo():\n",
        "    if torch.cuda.is_available():\n",
        "        return \"cuda\"\n",
        "    else:\n",
        "        return \"cpu\""
      ],
      "metadata": {
        "id": "KFWA2nqMNAbG"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def formatar_timestamp(segundos):\n",
        "    h, m = divmod(int(segundos), 3600)\n",
        "    m, s = divmod(m, 60)\n",
        "    return f\"{h:02}:{m:02}:{s:02}\""
      ],
      "metadata": {
        "id": "S1UScDPTNdfa"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remover_stopwords(texto):\n",
        "    try:\n",
        "        stopwords.words('portuguese')\n",
        "    except LookupError:\n",
        "        nltk.download('stopwords')\n",
        "\n",
        "    stop_words = set(stopwords.words(\"portuguese\"))\n",
        "    texto_sem_pontuacao = texto.translate(str.maketrans('', '', string.punctuation))\n",
        "    palavras = texto_sem_pontuacao.split()\n",
        "\n",
        "    palavras_filtradas = [\n",
        "        palavra for palavra in palavras\n",
        "        if palavra.lower() not in stop_words\n",
        "    ]\n",
        "    return \" \".join(palavras_filtradas)\n"
      ],
      "metadata": {
        "id": "oB8vtm_uNhaq"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcrever_audio(caminho_audio, modelo=\"base\", exportar=True, dispositivo=\"cpu\"):\n",
        "    if not os.path.exists(caminho_audio):\n",
        "        raise FileNotFoundError(f\"Arquivo n√£o encontrado: {caminho_audio}\")\n",
        "\n",
        "    print(f\"üîç Carregando modelo Whisper '{modelo}' no dispositivo {dispositivo.upper()}...\")\n",
        "    model = whisper.load_model(modelo).to(dispositivo)\n",
        "\n",
        "    print(\"üì° Transcrevendo √°udio...\")\n",
        "    resultado = model.transcribe(caminho_audio, verbose=False)\n",
        "\n",
        "    com_tempos = []\n",
        "    sem_tempos = []\n",
        "\n",
        "    for s in resultado['segments']:\n",
        "        texto = s['text'].strip()\n",
        "        com_tempos.append(f\"[{formatar_timestamp(s['start'])} - {formatar_timestamp(s['end'])}] {texto}\")\n",
        "        sem_tempos.append(texto)\n",
        "\n",
        "    texto_com_tempos = \"\\n\\n\".join(com_tempos)\n",
        "    texto_sem_tempos = \" \".join(sem_tempos)\n",
        "    texto_sem_tempos = remover_stopwords(texto_sem_tempos)\n",
        "\n",
        "    print(\"\\n‚úÖ Transcri√ß√£o finalizada!\\n\")\n",
        "    if exportar:\n",
        "        salvar_transcricoes(texto_com_tempos, texto_sem_tempos, caminho_audio)\n",
        "\n",
        "    return texto_com_tempos, texto_sem_tempos\n"
      ],
      "metadata": {
        "id": "bxMv535iNkf8"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def salvar_transcricoes(com_tempos, sem_tempos, caminho_audio):\n",
        "    base = os.path.splitext(os.path.basename(caminho_audio))[0]\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "    arquivos = {\n",
        "        f\"com_tempos_{base}_{timestamp}.txt\": com_tempos,\n",
        "        f\"sem_tempos_{base}_{timestamp}.txt\": sem_tempos\n",
        "    }\n",
        "\n",
        "    for nome, conteudo in arquivos.items():\n",
        "        with open(nome, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(conteudo)\n",
        "        print(f\"üìÅ Arquivo salvo: {nome}\")\n"
      ],
      "metadata": {
        "id": "0aMvqPS7NnVu"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mover_arquivos_processados(pasta_destino, base_nome):\n",
        "    extensoes = (\".txt\")\n",
        "    for arquivo in os.listdir(\".\"):\n",
        "        if base_nome in arquivo and arquivo.endswith(extensoes):\n",
        "            origem = os.path.join(\".\", arquivo)\n",
        "            destino = os.path.join(pasta_destino, arquivo)\n",
        "            shutil.move(origem, destino)\n",
        "            print(f\"üì¶ Arquivo movido: {arquivo}\")\n"
      ],
      "metadata": {
        "id": "xIMGitp6NqZg"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def escolher_arquivo_audio(diretorio):\n",
        "    arquivos_audio = [f for f in os.listdir(diretorio) if f.lower().endswith(('.mp3', '.wav', '.m4a'))]\n",
        "\n",
        "    if len(arquivos_audio) == 0:\n",
        "        print(\"‚ùå Nenhum arquivo de √°udio encontrado na raiz.\")\n",
        "        return None\n",
        "\n",
        "    if len(arquivos_audio) == 1:\n",
        "        return arquivos_audio[0]\n",
        "\n",
        "    print(\"üîä M√∫ltiplos arquivos de √°udio encontrados. Escolha um para processar via flag --audio.\")\n",
        "    print('Ver documenta√ß√£o.')\n",
        "    return (2/0)/0\n"
      ],
      "metadata": {
        "id": "hne6HbRMNs-6"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcrever_Resumir(diretorio):\n",
        "    arquivo_audio = escolher_arquivo_audio(diretorio)\n",
        "\n",
        "    if arquivo_audio:\n",
        "        caminho_audio = os.path.join(diretorio, arquivo_audio)\n",
        "        modelo = Modelo\n",
        "        dispositivo = escolher_dispositivo()\n",
        "\n",
        "        nome_arquivo_sem_ext = os.path.splitext(arquivo_audio)[0]\n",
        "        pasta_destino = os.path.join(\"aulas_processadas\", nome_arquivo_sem_ext)\n",
        "\n",
        "        if os.path.exists(pasta_destino):\n",
        "            print(f\"‚ö†Ô∏è Sobrescrevendo\")\n",
        "        else:\n",
        "            os.makedirs(pasta_destino)\n",
        "\n",
        "        try:\n",
        "            withTime, noTime = transcrever_audio(caminho_audio, modelo=modelo, exportar=True, dispositivo=dispositivo)\n",
        "\n",
        "            print(\"\\nüìù Criando resumo\")\n",
        "            tituloMD, resumoMD = gerar_resumo_markdown(noTime)\n",
        "            print(\"\\n‚úÖ Resumo pronto!\")\n",
        "\n",
        "            print(\"\\nüìù Criando guia de estudos\")\n",
        "            tituloGuia, guiaEstudos = gerar_guia_estudos_markdown(resumoMD)\n",
        "            print(\"\\n‚úÖ Guia de estudos pronto!\")\n",
        "\n",
        "            print(\"\\nüìù Criando quest√µes\")\n",
        "            tituloQuestoes, QuestoesMD = gerar_questoes_markdown(resumoMD)\n",
        "            print(\"\\n‚úÖ Quest√µes prontas!\")\n",
        "\n",
        "            gerar_pdf_markdown(resumoMD, pasta_destino, \"resumo.pdf\")\n",
        "            gerar_pdf_markdown(guiaEstudos, pasta_destino, \"guia.pdf\")\n",
        "            gerar_pdf_markdown(QuestoesMD, pasta_destino, \"questoes.pdf\")\n",
        "\n",
        "            # Mover os arquivos usados para a pasta destino\n",
        "            mover_arquivos_processados(pasta_destino, nome_arquivo_sem_ext)\n",
        "\n",
        "            # Criar um arquivo ZIP com os arquivos processados\n",
        "            zip_filename = f\"{nome_arquivo_sem_ext}_aulas.zip\"\n",
        "            shutil.make_archive(zip_filename, 'zip', pasta_destino)\n",
        "\n",
        "            # Fazer o download do arquivo ZIP\n",
        "            files.download(f\"{zip_filename}.zip\")\n",
        "\n",
        "        except Exception as erro:\n",
        "            print(f\"‚ùå Erro: {erro}\")"
      ],
      "metadata": {
        "id": "IQ29xdEjRmAP"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execu√ß√£o"
      ],
      "metadata": {
        "id": "K0vfXh7zRarj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transcrever_Resumir('.')"
      ],
      "metadata": {
        "id": "61k5k3JfN-WN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}