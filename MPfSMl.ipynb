{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "Modelo = \"medium\" # @param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6Frc5sa7N-IN"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Código\n",
        "Não precisa mexer, aqui tem os prompts, caso queira alterar."
      ],
      "metadata": {
        "id": "CUr5XDKOSCAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalação das Biliotecas"
      ],
      "metadata": {
        "id": "gpAcb1VmMT_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install whisper weasyprint"
      ],
      "metadata": {
        "id": "eDgZx_fOMMta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ed8d98-73a0-4ff4-e70a-14a37b5b7097"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: whisper in /usr/local/lib/python3.11/dist-packages (1.1.10)\n",
            "Requirement already satisfied: weasyprint in /usr/local/lib/python3.11/dist-packages (65.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from whisper) (1.17.0)\n",
            "Requirement already satisfied: pydyf>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (0.11.0)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (1.17.1)\n",
            "Requirement already satisfied: tinyhtml5>=2.0.0b1 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (2.0.0)\n",
            "Requirement already satisfied: tinycss2>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (1.4.0)\n",
            "Requirement already satisfied: cssselect2>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (0.8.0)\n",
            "Requirement already satisfied: Pyphen>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (0.17.2)\n",
            "Requirement already satisfied: Pillow>=9.1.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (11.1.0)\n",
            "Requirement already satisfied: fonttools>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (4.57.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=0.6->weasyprint) (2.22)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from cssselect2>=0.8.0->weasyprint) (0.5.1)\n",
            "Requirement already satisfied: brotli>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (1.1.0)\n",
            "Requirement already satisfied: zopfli>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (0.2.3.post1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper"
      ],
      "metadata": {
        "id": "ChKyonQ3G5yo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "febc40c0-a07d-48de-e5bf-76c6be2871d0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "VCkLMWPYLo3E"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import argparse\n",
        "import os\n",
        "from datetime import datetime\n",
        "import torch\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import requests\n",
        "import markdown\n",
        "from weasyprint import HTML\n",
        "import shutil\n",
        "from google.colab import userdata\n",
        "from google.colab import files\n",
        "\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={API_KEY}\""
      ],
      "metadata": {
        "id": "KJNrXlH-MHBl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notion_style = \"\"\"\n",
        "<style>\n",
        "  body {\n",
        "      font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial, sans-serif, \"Segoe UI Emoji\", \"Apple Color Emoji\";\n",
        "      max-width: 800px;\n",
        "      margin: 10px auto;\n",
        "      padding: 10px;\n",
        "      line-height: 1.6;\n",
        "      font-size: 16px;\n",
        "      color: #2e2e2e;\n",
        "      background: #ffffff;\n",
        "  }\n",
        "    h1, h2, h3 {\n",
        "        border-bottom: 1px solid #eaeaea;\n",
        "        padding-bottom: 0.3em;\n",
        "        margin-top: 1.4em;\n",
        "    }\n",
        "    code {\n",
        "        background-color: #f6f8fa;\n",
        "        padding: 2px 4px;\n",
        "        border-radius: 3px;\n",
        "        font-size: 90%;\n",
        "        font-family: SFMono-Regular, Consolas, Liberation Mono, Menlo, monospace;\n",
        "    }\n",
        "    pre code {\n",
        "        background-color: #f6f8fa;\n",
        "        display: block;\n",
        "        padding: 1em;\n",
        "        overflow-x: auto;\n",
        "    }\n",
        "    blockquote {\n",
        "        border-left: 4px solid #dfe2e5;\n",
        "        padding: 0 1em;\n",
        "        color: #6a737d;\n",
        "    }\n",
        "    table {\n",
        "        border-collapse: collapse;\n",
        "        width: 100%;\n",
        "    }\n",
        "    th, td {\n",
        "        border: 1px solid #dfe2e5;\n",
        "        padding: 6px 13px;\n",
        "    }\n",
        "    th {\n",
        "        background-color: #f6f8fa;\n",
        "    }\n",
        "    @page {\n",
        "        margin: 10mm;\n",
        "    }\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "63CBt_yQMpN5"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def argumentos_cli():\n",
        "    parser = argparse.ArgumentParser(description=\"Transcrição e resumo de aulas com Whisper + Gemini\")\n",
        "\n",
        "    parser.add_argument('--audio', type=str, help='Caminho para o arquivo de áudio a ser processado')\n",
        "    parser.add_argument('--modelo', type=str, default='base', help='Modelo do Whisper a ser usado (base, small, medium, large, etc.)')\n",
        "\n",
        "    return parser.parse_args()\n"
      ],
      "metadata": {
        "id": "u60zOcwAMsn6"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_pdf_markdown(markdown_text, pasta_destino, nome_pdf):\n",
        "    html_content = markdown.markdown(markdown_text, extensions=[\"extra\", \"tables\", \"fenced_code\"])\n",
        "    full_html = f\"<!DOCTYPE html><html><head><meta charset='utf-8'>{notion_style}</head><body>{html_content}</body></html>\"\n",
        "    caminho_pdf = os.path.join(pasta_destino, nome_pdf)\n",
        "    HTML(string=full_html).write_pdf(caminho_pdf)\n",
        "    print(f\"✅ PDF gerado com sucesso: {caminho_pdf}\")"
      ],
      "metadata": {
        "id": "ZkIV-LEhM0jO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts enviados ao gemini"
      ],
      "metadata": {
        "id": "KzYluOjJMl4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_guia_estudos_markdown(transcricao: str) -> tuple[str, str]:\n",
        "    prompt_estudo = f\"\"\"\n",
        "A partir do conteúdo abaixo (resumo), crie uma guia de estudos personalizada em formato Markdown, com foco em aprendizado acadêmico e médico.\n",
        "\n",
        "A resposta será convertida em PDF, então:\n",
        "\n",
        "- Use formatação Markdown limpa\n",
        "- Use títulos, listas e divisões visuais claras\n",
        "- Não inclua elementos interativos ou links clicáveis\n",
        "\n",
        "Contexto essencial:\n",
        "\n",
        "Este resumo foi gerado a partir de um sistema automatizado que converte áudios de estudo em texto. A partir dele, serão produzidos:\n",
        "\n",
        "- Questões objetivas e clínicas, classificadas por dificuldade\n",
        "- Flashcards com os principais pontos e termos\n",
        "\n",
        "Por isso, a guia de estudos deve:\n",
        "\n",
        "- Indicar os conhecimentos prévios essenciais para compreender o tema\n",
        "- Apresentar um checklist organizado com o que estudar primeiro\n",
        "- Explicar como e quando utilizar as questões e flashcards gerados\n",
        "- Evitar sugestões genéricas como \"ensinar a alguém\" ou \"fazer resumos próprios\"\n",
        "\n",
        "A estrutura da resposta deve ser:\n",
        "\n",
        "# Guia de Estudos: [Tema do Resumo]\n",
        "\n",
        "## Visão Geral\n",
        "Descreva em poucas linhas o tema central e sua relevância médica.\n",
        "\n",
        "## Pré-requisitos\n",
        "Liste tópicos que o estudante deve dominar antes de aprofundar o conteúdo. Ex: anatomia relacionada, princípios básicos, etc.\n",
        "\n",
        "## Checklist de Estudo\n",
        "Organize os principais pontos do conteúdo em forma de lista ordenada. Cada item deve representar uma etapa de estudo.\n",
        "\n",
        "## Aplicação Direta\n",
        "Oriente o estudante a:\n",
        "\n",
        "- Usar as questões geradas para treinar sua compreensão e identificar lacunas\n",
        "- Utilizar os flashcards para revisão contínua e memorização\n",
        "- Revisar frequentemente os erros nas questões para reforçar áreas frágeis\n",
        "\n",
        "Não inclua sugestões genéricas como ensinar o conteúdo para outra pessoa.\n",
        "\n",
        "## Plano de Estudo Sugerido\n",
        "Organize um cronograma de revisão dividido por dias (ex: 3, 7 ou 14 dias), integrando o uso das questões e dos flashcards gerados com o resumo.\n",
        "\n",
        "Resumo para base do estudo:\n",
        "{transcricao}\n",
        "\"\"\"\n",
        "\n",
        "    data = {\"contents\": [{\"parts\": [{\"text\": prompt_estudo}]}]}\n",
        "\n",
        "    response = requests.post(URL, headers=headers, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        markdown_raw = result['candidates'][0]['content']['parts'][0]['text']\n",
        "\n",
        "        markdown_clean = markdown_raw.strip().split(\"\\n\", 1)[-1].strip()  # Clean and trim the result\n",
        "\n",
        "        titulo = next((line.strip(\"# \").strip() for line in markdown_clean.split(\"\\n\") if line.startswith(\"# \")), \"Guia\")\n",
        "        return f\"{titulo}.pdf\", markdown_clean\n",
        "    else:\n",
        "        raise Exception(f\"Erro na requisição: {response.status_code}\\n{response.text}\")\n"
      ],
      "metadata": {
        "id": "o1YK3vkeM4_o"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_resumo_markdown(transcricao: str) -> tuple[str, str]:\n",
        "    prompt = f\"\"\"\n",
        "Sem fornecer nenhum tipo de feedback, comentário ou explicação adicional, gere um resumo completo e didático da transcrição da aula que vou enviar a seguir. O objetivo é facilitar a compreensão de um aluno de medicina, então complemente com informações relevantes sempre que considerar útil para a assimilação do conteúdo.\n",
        "\n",
        "O resumo deve ser entregue em Markdown puro, como se fosse um código-fonte, com títulos estilizados com emojis, no estilo visual do Notion.\n",
        "\n",
        "Apenas retorne o conteúdo em Markdown, sem nenhuma outra resposta textual.\n",
        "\n",
        "Transcrição da aula:\n",
        "{transcricao}\n",
        "\"\"\"\n",
        "\n",
        "    data = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"parts\": [\n",
        "                    {\"text\": prompt}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(URL, headers=headers, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        markdown_raw = result['candidates'][0]['content']['parts'][0]['text']\n",
        "\n",
        "        if markdown_raw.startswith(\"```markdown\") and markdown_raw.endswith(\"```\"):\n",
        "            markdown_clean = \"\\n\".join(markdown_raw.strip().split(\"\\n\")[1:-1])\n",
        "        else:\n",
        "            markdown_clean = markdown_raw\n",
        "\n",
        "        titulo = \"\"\n",
        "        for line in markdown_clean.split(\"\\n\"):\n",
        "            if line.strip().startswith(\"# \"):\n",
        "                titulo = line.strip(\"# \").strip()\n",
        "                break\n",
        "\n",
        "        titulo = titulo + '.pdf'\n",
        "        return titulo, markdown_clean\n",
        "    else:\n",
        "        raise Exception(f\"Erro na requisição: {response.status_code}\\n{response.text}\")\n"
      ],
      "metadata": {
        "id": "LaweMHgvJ1cx"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_resumo_markdown(transcricao: str) -> tuple[str, str]:\n",
        "    prompt = f\"\"\"\n",
        "Sem fornecer nenhum tipo de feedback, comentário ou explicação adicional, gere um resumo completo e didático da transcrição da aula que vou enviar a seguir. O objetivo é facilitar a compreensão de um aluno de medicina, então complemente com informações relevantes sempre que considerar útil para a assimilação do conteúdo.\n",
        "\n",
        "O resumo deve ser entregue em Markdown puro, como se fosse um código-fonte, com títulos estilizados com emojis, no estilo visual do Notion.\n",
        "\n",
        "Apenas retorne o conteúdo em Markdown, sem nenhuma outra resposta textual.\n",
        "\n",
        "Transcrição da aula:\n",
        "{transcricao}\n",
        "\"\"\"\n",
        "\n",
        "    data = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"parts\": [\n",
        "                    {\"text\": prompt}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(URL, headers=headers, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        markdown_raw = result['candidates'][0]['content']['parts'][0]['text']\n",
        "\n",
        "        if markdown_raw.startswith(\"```markdown\") and markdown_raw.endswith(\"```\"):\n",
        "            markdown_clean = \"\\n\".join(markdown_raw.strip().split(\"\\n\")[1:-1])\n",
        "        else:\n",
        "            markdown_clean = markdown_raw\n",
        "\n",
        "        titulo = \"\"\n",
        "        for line in markdown_clean.split(\"\\n\"):\n",
        "            if line.strip().startswith(\"# \"):\n",
        "                titulo = line.strip(\"# \").strip()\n",
        "                break\n",
        "\n",
        "        titulo = titulo + '.pdf'\n",
        "        return titulo, markdown_clean\n",
        "    else:\n",
        "        raise Exception(f\"Erro na requisição: {response.status_code}\\n{response.text}\")\n"
      ],
      "metadata": {
        "id": "ZULuRHcmJy5E"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_resumo_markdown(transcricao: str) -> tuple[str, str]:\n",
        "    prompt = f\"\"\"\n",
        "Sem fornecer nenhum tipo de feedback, comentário ou explicação adicional, gere um resumo completo e didático da transcrição da aula que vou enviar a seguir. O objetivo é facilitar a compreensão de um aluno de medicina, então complemente com informações relevantes sempre que considerar útil para a assimilação do conteúdo.\n",
        "\n",
        "O resumo deve ser entregue em Markdown puro, como se fosse um código-fonte, com títulos estilizados com emojis, no estilo visual do Notion.\n",
        "\n",
        "Apenas retorne o conteúdo em Markdown, sem nenhuma outra resposta textual.\n",
        "\n",
        "Transcrição da aula:\n",
        "{transcricao}\n",
        "\"\"\"\n",
        "\n",
        "    data = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"parts\": [\n",
        "                    {\"text\": prompt}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(URL, headers=headers, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        markdown_raw = result['candidates'][0]['content']['parts'][0]['text']\n",
        "\n",
        "        if markdown_raw.startswith(\"```markdown\") and markdown_raw.endswith(\"```\"):\n",
        "            markdown_clean = \"\\n\".join(markdown_raw.strip().split(\"\\n\")[1:-1])\n",
        "        else:\n",
        "            markdown_clean = markdown_raw\n",
        "\n",
        "        titulo = \"\"\n",
        "        for line in markdown_clean.split(\"\\n\"):\n",
        "            if line.strip().startswith(\"# \"):\n",
        "                titulo = line.strip(\"# \").strip()\n",
        "                break\n",
        "\n",
        "        titulo = titulo + '.pdf'\n",
        "        return titulo, markdown_clean\n",
        "    else:\n",
        "        raise Exception(f\"Erro na requisição: {response.status_code}\\n{response.text}\")\n"
      ],
      "metadata": {
        "id": "riDGipHGM9X2"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_questoes_markdown(texto_base):\n",
        "    prompt = f\"\"\"\n",
        "    A partir do conteúdo abaixo, crie 10 questões de cada nível de dificuldade (fácil, médio, difícil), com foco em reforço de compreensão médica e acadêmica. Siga as regras:\n",
        "\n",
        "    - Crie 10 questões fáceis, 10 médias e 10 difíceis.\n",
        "    - Não agrupe as questões em fáceis, médias ou dificeis, o aluno só deve saber ao ver o gabarito.\n",
        "    - Faça da questão 01 até a 30, sem agrupar por dificuldade.\n",
        "    - As respostas das questões devem estar APENAS excluivamente na área de gabaritos.\n",
        "    - As questões devem ser formuladas em formatos variados:\n",
        "      - Questões objetivas (com alternativas)\n",
        "      - Questões de resposta curta\n",
        "      - Questões de verdadeiro ou falso\n",
        "      - Casos clínicos\n",
        "\n",
        "    - As alternativas, ou as respostas curtas, devem ser realistas e educativas, com a resposta correta claramente identificada.\n",
        "    - As alternativas devem ser equilibradas em dificuldade, sem nenhuma óbvia ou excessivamente fácil.\n",
        "    - Cada questão deve ser seguida de justificativa detalhada explicando o raciocínio por trás da resposta correta.\n",
        "    - Não forneça explicações adicionais além das instruções acima.\n",
        "\n",
        "    A saída deve estar no formato Markdown, com as questões bem organizadas e agradáveis para visualização e impressão. Evite usar links e mantenha a formatação simples, para que as questões sejam facilmente legíveis e prontas para serem impressas. As alternativas devem ser listadas de forma clara, e cada justificativa deve vir logo após a questão correspondente.\n",
        "\n",
        "    Para as questões de resposta curta, inclua um espaço de linhas (sublinhado) do tamanho necessário para a resposta, usando a seguinte formatação:\n",
        "    ________________________\n",
        "\n",
        "    Saída: Responda no formato Markdown com as seguintes informações:\n",
        "\n",
        "    ### Questões:\n",
        "\n",
        "    1.  **Pergunta:** (enunciado da questão)\n",
        "       - Alternativas:\n",
        "         - A) Alternativa 1\n",
        "         - B) Alternativa 2\n",
        "         - C) Alternativa 3\n",
        "         - D) Alternativa 4\n",
        "         - E) Alternativa 5\n",
        "\n",
        "    2.  **Pergunta:** (enunciado da questão)\n",
        "       - Alternativas:\n",
        "         - A) Verdadeiro\n",
        "         - B) Falso (justificar aqui:______________________________)\n",
        "\n",
        "    3. **Pergunta:** (enunciado da questão)\n",
        "       **Resposta:**\n",
        "       _____________________________________________________________\n",
        "\n",
        "    Repita as 30 questões, seguindo o mesmo formato\n",
        "\n",
        "    ### Gabarito:\n",
        "    1. **Resposta:** A\n",
        "       **Justificativa:** Explicação detalhada do porquê a alternativa A é a correta.\n",
        "       **Nível: fácil/médio/difícil**\n",
        "\n",
        "    2. **Resposta:** B\n",
        "       **Justificativa:** Explicação detalhada do porquê a alternativa B é a correta.\n",
        "       **Nível: fácil/médio/difícil**\n",
        "\n",
        "    3. **Resposta:** Falso\n",
        "       **Justificativa:** Explicação detalhada do que tornou a questão falsa ou verdadeira.\n",
        "       **Nível: fácil/médio/difícil**\n",
        "\n",
        "    (Repita para todas as questões)\n",
        "\n",
        "    ### Texto base:\n",
        "    {texto_base}\n",
        "    \"\"\"\n",
        "    data = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n",
        "\n",
        "    response = requests.post(URL, headers=headers, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        markdown_raw = result['candidates'][0]['content']['parts'][0]['text']\n",
        "\n",
        "        markdown_clean = markdown_raw.strip().split(\"\\n\", 1)[-1].strip()  # Clean and trim the result\n",
        "\n",
        "        titulo = 'questoes'\n",
        "        return f\"{titulo}.pdf\", markdown_clean\n",
        "    else:\n",
        "        raise Exception(f\"Erro na requisição: {response.status_code}\\n{response.text}\")"
      ],
      "metadata": {
        "id": "5yuQ3rtdM2YZ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execução da Transcrição e Passagem ao PDF."
      ],
      "metadata": {
        "id": "5CQDMTsaM8K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def escolher_dispositivo():\n",
        "    if torch.cuda.is_available():\n",
        "        return \"cuda\"\n",
        "    else:\n",
        "        return \"cpu\""
      ],
      "metadata": {
        "id": "KFWA2nqMNAbG"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def formatar_timestamp(segundos):\n",
        "    h, m = divmod(int(segundos), 3600)\n",
        "    m, s = divmod(m, 60)\n",
        "    return f\"{h:02}:{m:02}:{s:02}\""
      ],
      "metadata": {
        "id": "S1UScDPTNdfa"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remover_stopwords(texto):\n",
        "    try:\n",
        "        stopwords.words('portuguese')\n",
        "    except LookupError:\n",
        "        nltk.download('stopwords')\n",
        "\n",
        "    stop_words = set(stopwords.words(\"portuguese\"))\n",
        "    texto_sem_pontuacao = texto.translate(str.maketrans('', '', string.punctuation))\n",
        "    palavras = texto_sem_pontuacao.split()\n",
        "\n",
        "    palavras_filtradas = [\n",
        "        palavra for palavra in palavras\n",
        "        if palavra.lower() not in stop_words\n",
        "    ]\n",
        "    return \" \".join(palavras_filtradas)\n"
      ],
      "metadata": {
        "id": "oB8vtm_uNhaq"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcrever_audio(caminho_audio, modelo=\"base\", exportar=True, dispositivo=\"cpu\"):\n",
        "    if not os.path.exists(caminho_audio):\n",
        "        raise FileNotFoundError(f\"Arquivo não encontrado: {caminho_audio}\")\n",
        "\n",
        "    print(f\"🔍 Carregando modelo Whisper '{modelo}' no dispositivo {dispositivo.upper()}...\")\n",
        "    model = whisper.load_model(modelo).to(dispositivo)\n",
        "\n",
        "    print(\"📡 Transcrevendo áudio...\")\n",
        "    resultado = model.transcribe(caminho_audio, verbose=False)\n",
        "\n",
        "    com_tempos = []\n",
        "    sem_tempos = []\n",
        "\n",
        "    for s in resultado['segments']:\n",
        "        texto = s['text'].strip()\n",
        "        com_tempos.append(f\"[{formatar_timestamp(s['start'])} - {formatar_timestamp(s['end'])}] {texto}\")\n",
        "        sem_tempos.append(texto)\n",
        "\n",
        "    texto_com_tempos = \"\\n\\n\".join(com_tempos)\n",
        "    texto_sem_tempos = \" \".join(sem_tempos)\n",
        "    texto_sem_tempos = remover_stopwords(texto_sem_tempos)\n",
        "\n",
        "    print(\"\\n✅ Transcrição finalizada!\\n\")\n",
        "    if exportar:\n",
        "        salvar_transcricoes(texto_com_tempos, texto_sem_tempos, caminho_audio)\n",
        "\n",
        "    return texto_com_tempos, texto_sem_tempos\n"
      ],
      "metadata": {
        "id": "bxMv535iNkf8"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def salvar_transcricoes(com_tempos, sem_tempos, caminho_audio):\n",
        "    base = os.path.splitext(os.path.basename(caminho_audio))[0]\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "    arquivos = {\n",
        "        f\"com_tempos_{base}_{timestamp}.txt\": com_tempos,\n",
        "        f\"sem_tempos_{base}_{timestamp}.txt\": sem_tempos\n",
        "    }\n",
        "\n",
        "    for nome, conteudo in arquivos.items():\n",
        "        with open(nome, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(conteudo)\n",
        "        print(f\"📁 Arquivo salvo: {nome}\")\n"
      ],
      "metadata": {
        "id": "0aMvqPS7NnVu"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mover_arquivos_processados(pasta_destino, base_nome):\n",
        "    extensoes = (\".txt\")\n",
        "    for arquivo in os.listdir(\".\"):\n",
        "        if base_nome in arquivo and arquivo.endswith(extensoes):\n",
        "            origem = os.path.join(\".\", arquivo)\n",
        "            destino = os.path.join(pasta_destino, arquivo)\n",
        "            shutil.move(origem, destino)\n",
        "            print(f\"📦 Arquivo movido: {arquivo}\")\n"
      ],
      "metadata": {
        "id": "xIMGitp6NqZg"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def escolher_arquivo_audio(diretorio):\n",
        "    arquivos_audio = [f for f in os.listdir(diretorio) if f.lower().endswith(('.mp3', '.wav', '.m4a'))]\n",
        "\n",
        "    if len(arquivos_audio) == 0:\n",
        "        print(\"❌ Nenhum arquivo de áudio encontrado na raiz.\")\n",
        "        return None\n",
        "\n",
        "    if len(arquivos_audio) == 1:\n",
        "        return arquivos_audio[0]\n",
        "\n",
        "    print(\"🔊 Múltiplos arquivos de áudio encontrados. Escolha um para processar via flag --audio.\")\n",
        "    print('Ver documentação.')\n",
        "    return (2/0)/0\n"
      ],
      "metadata": {
        "id": "hne6HbRMNs-6"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcrever_Resumir(diretorio):\n",
        "    arquivo_audio = escolher_arquivo_audio(diretorio)\n",
        "\n",
        "    if arquivo_audio:\n",
        "        caminho_audio = os.path.join(diretorio, arquivo_audio)\n",
        "        modelo = Modelo\n",
        "        dispositivo = escolher_dispositivo()\n",
        "\n",
        "        nome_arquivo_sem_ext = os.path.splitext(arquivo_audio)[0]\n",
        "        pasta_destino = os.path.join(\"aulas_processadas\", nome_arquivo_sem_ext)\n",
        "\n",
        "        if os.path.exists(pasta_destino):\n",
        "            print(f\"⚠️ Sobrescrevendo\")\n",
        "        else:\n",
        "            os.makedirs(pasta_destino)\n",
        "\n",
        "        try:\n",
        "            withTime, noTime = transcrever_audio(caminho_audio, modelo=modelo, exportar=True, dispositivo=dispositivo)\n",
        "\n",
        "            print(\"\\n📝 Criando resumo\")\n",
        "            tituloMD, resumoMD = gerar_resumo_markdown(noTime)\n",
        "            print(\"\\n✅ Resumo pronto!\")\n",
        "\n",
        "            print(\"\\n📝 Criando guia de estudos\")\n",
        "            tituloGuia, guiaEstudos = gerar_guia_estudos_markdown(resumoMD)\n",
        "            print(\"\\n✅ Guia de estudos pronto!\")\n",
        "\n",
        "            print(\"\\n📝 Criando questões\")\n",
        "            tituloQuestoes, QuestoesMD = gerar_questoes_markdown(resumoMD)\n",
        "            print(\"\\n✅ Questões prontas!\")\n",
        "\n",
        "            gerar_pdf_markdown(resumoMD, pasta_destino, \"resumo.pdf\")\n",
        "            gerar_pdf_markdown(guiaEstudos, pasta_destino, \"guia.pdf\")\n",
        "            gerar_pdf_markdown(QuestoesMD, pasta_destino, \"questoes.pdf\")\n",
        "\n",
        "            # Mover os arquivos usados para a pasta destino\n",
        "            mover_arquivos_processados(pasta_destino, nome_arquivo_sem_ext)\n",
        "\n",
        "            # Criar um arquivo ZIP com os arquivos processados\n",
        "            zip_filename = f\"{nome_arquivo_sem_ext}_aulas.zip\"\n",
        "            shutil.make_archive(zip_filename, 'zip', pasta_destino)\n",
        "\n",
        "            # Fazer o download do arquivo ZIP\n",
        "            files.download(f\"{zip_filename}.zip\")\n",
        "\n",
        "        except Exception as erro:\n",
        "            print(f\"❌ Erro: {erro}\")"
      ],
      "metadata": {
        "id": "IQ29xdEjRmAP"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execução"
      ],
      "metadata": {
        "id": "K0vfXh7zRarj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transcrever_Resumir('.')"
      ],
      "metadata": {
        "id": "61k5k3JfN-WN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}